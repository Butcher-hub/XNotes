import{_ as a,c as s,o as i,a1 as e,a2 as t,a3 as l,a4 as h,a5 as p,a6 as n,a7 as o,a8 as d,a9 as r,aa as k,ab as c,ac as g,ad as u,ae as b,af as F,ag as y,ah as m}from"./chunks/framework.lh4d3Jpg.js";const H=JSON.parse('{"title":"1、概念","description":"","frontmatter":{},"headers":[],"relativePath":"大数据/hadoop/02 hadoop入门.md","filePath":"大数据/hadoop/02 hadoop入门.md"}'),E={name:"大数据/hadoop/02 hadoop入门.md"},_=e('<h1 id="_1、概念" tabindex="-1">1、概念 <a class="header-anchor" href="#_1、概念" aria-label="Permalink to &quot;1、概念&quot;">​</a></h1><h2 id="hadoop是什么" tabindex="-1">hadoop是什么？ <a class="header-anchor" href="#hadoop是什么" aria-label="Permalink to &quot;hadoop是什么？&quot;">​</a></h2><ul><li>hadoop是有apache基金会所开发的<strong>分布式系统基础架构</strong></li><li>主要解决，海量数据存储与分析</li></ul><h2 id="hadoop发展历史" tabindex="-1">hadoop发展历史 <a class="header-anchor" href="#hadoop发展历史" aria-label="Permalink to &quot;hadoop发展历史&quot;">​</a></h2><p><img src="'+t+'" alt="输入图片说明"><img src="'+l+'" alt="输入图片说明"></p><h2 id="hadoop三大发行版本" tabindex="-1">hadoop三大发行版本 <a class="header-anchor" href="#hadoop三大发行版本" aria-label="Permalink to &quot;hadoop三大发行版本&quot;">​</a></h2><p><img src="'+h+'" alt="输入图片说明"></p><h2 id="hadoop优势" tabindex="-1">hadoop优势 <a class="header-anchor" href="#hadoop优势" aria-label="Permalink to &quot;hadoop优势&quot;">​</a></h2><p><img src="'+p+'" alt="输入图片说明"><img src="'+n+'" alt="输入图片说明"></p><h2 id="hadoop组成" tabindex="-1">hadoop组成 <a class="header-anchor" href="#hadoop组成" aria-label="Permalink to &quot;hadoop组成&quot;">​</a></h2><p><img src="'+o+'" alt="输入图片说明"></p><h3 id="hdfs" tabindex="-1">HDFS <a class="header-anchor" href="#hdfs" aria-label="Permalink to &quot;HDFS&quot;">​</a></h3><p>Hadoop Distributed File System 简称 HDFS，是一个分布式的文件系统。</p><p>1） NameNode （nn）: 存储文件的<strong>元数据</strong>，如文件名、文件目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的<strong>DataNode</strong>等</p><p>2）DataNde（dn）: 在本地文件系统存储文件块数据，以及块数据的校验。</p><p>3）Secondary NameNode（2nn）：每隔一段时间对NameNode元数据备份</p><p><img src="'+d+'" alt="输入图片说明"></p><h3 id="yarn" tabindex="-1">YARN <a class="header-anchor" href="#yarn" aria-label="Permalink to &quot;YARN&quot;">​</a></h3><p>Yet Another Resource Negotiator 简称YRAN，另一种资源协调者，是Hadoop的资源管理器。，主要管理CPU和内存。 <img src="'+r+'" alt="输入图片说明"></p><h3 id="mapreduce" tabindex="-1">MapReduce <a class="header-anchor" href="#mapreduce" aria-label="Permalink to &quot;MapReduce&quot;">​</a></h3><p>MapReduce将计算分为两个阶段：Map 和Reduce</p><p>1）Map阶段并行处理输入数据</p><p>2）Reduce节点对Map结果进行汇总</p><h3 id="三者的关系" tabindex="-1">三者的关系 <a class="header-anchor" href="#三者的关系" aria-label="Permalink to &quot;三者的关系&quot;">​</a></h3><p><img src="'+k+'" alt="输入图片说明"></p><h2 id="大数据技术生态体系" tabindex="-1">大数据技术生态体系 <a class="header-anchor" href="#大数据技术生态体系" aria-label="Permalink to &quot;大数据技术生态体系&quot;">​</a></h2><p><img src="'+c+'" alt="输入图片说明"></p><h1 id="_2、环境准备" tabindex="-1">2、环境准备 <a class="header-anchor" href="#_2、环境准备" aria-label="Permalink to &quot;2、环境准备&quot;">​</a></h1><h2 id="模板虚拟机准备" tabindex="-1">模板虚拟机准备 <a class="header-anchor" href="#模板虚拟机准备" aria-label="Permalink to &quot;模板虚拟机准备&quot;">​</a></h2><p>为了后续能克隆出多台虚拟机。</p><h3 id="安装操作系统" tabindex="-1">安装操作系统 <a class="header-anchor" href="#安装操作系统" aria-label="Permalink to &quot;安装操作系统&quot;">​</a></h3><ul><li>自定义</li><li>稍后安装操作系统</li><li>Linux</li><li>虚拟机名称</li><li>处理器2核4g</li><li>内存4g</li><li>50g</li><li>设置主机名称</li><li>开启网络</li></ul><h3 id="网络设置" tabindex="-1">网络设置 <a class="header-anchor" href="#网络设置" aria-label="Permalink to &quot;网络设置&quot;">​</a></h3><p>VM Ware / 编辑 / 虚拟网络编辑器</p><p><img src="'+g+'" alt="输入图片说明"> Windows上设置网络适配器 <img src="'+u+'" alt="输入图片说明"><img src="'+b+`" alt="输入图片说明"> 设置虚拟机网络</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/sysconfig/network-scripts/ifcfg-ens33</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 修改</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">BOOTPROTO</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;static&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 添加</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">IPADDR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">192.168.10.100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">GATEWAY</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">192.168.10.2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">DNS1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">192.168.10.2</span></span></code></pre></div><p>修改主机名</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/hostname</span></span></code></pre></div><p>设置ip映射</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/hosts</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 添加 </span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">192.168.10.100</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop100</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">192.168.10.101</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop101</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">192.168.10.102</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop102</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">192.168.10.103</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop103</span></span></code></pre></div><p>修改windows hosts文件 C:\\Windows\\System32\\drivers\\etc\\hosts</p><h2 id="安装准备" tabindex="-1">安装准备 <a class="header-anchor" href="#安装准备" aria-label="Permalink to &quot;安装准备&quot;">​</a></h2><h3 id="安装epel-release" tabindex="-1">安装epel-release <a class="header-anchor" href="#安装epel-release" aria-label="Permalink to &quot;安装epel-release&quot;">​</a></h3><p>Extra Packages for Enterprise Linux 是为“红帽系“的操作系统提供的额外软件包，适用于RHEL、CentOS和Scientific Linux。相当于是一个软件仓库，大多数rmp包在官方repository中是找不到的。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> epel-release</span></span></code></pre></div><p>如果Linux安装的是最小系统版，还需要安装如下工具</p><ul><li>net-tool: 工具包集合，包含ifconfig命令 <code>yum install -y net-tools</code></li><li>vim 编辑器 <code>yum install -y vim</code></li></ul><blockquote><p><code>-y</code>: 这是一个选项，表示自动确认所有的提示。在执行安装过程中，YUM有时会询问用户是否确认安装即将进行的操作。加上<code>-y</code>参数后，YUM会默认回答“是”（yes）对所有提问，从而使得整个安装过程自动化，无需人工干预。这对于脚本自动化安装特别有用，避免了在无人值守的情况下需要手动确认每一个步骤。</p></blockquote><h3 id="关闭防火墙" tabindex="-1">关闭防火墙 <a class="header-anchor" href="#关闭防火墙" aria-label="Permalink to &quot;关闭防火墙&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 关闭防火墙</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">systemctl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> stop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> firewalld</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 关闭防火墙开机自启</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">systemctl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> disaable</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> firewalld.service</span></span></code></pre></div><p>在企业内部，一般内部的机子都不开防火墙，只在公司对外网络使用防火墙。</p><p><img src="`+F+'" alt="输入图片说明"><img src="'+y+'" alt="输入图片说明"><img src="'+m+`" alt="输入图片说明"></p><h2 id="克隆" tabindex="-1">克隆 <a class="header-anchor" href="#克隆" aria-label="Permalink to &quot;克隆&quot;">​</a></h2><p>分别基于hadoop100克隆出 hadoop102、hadoop103、hadoop104 并分别修改主机名与IP地址</p><h2 id="安装jdk、hadoop" tabindex="-1">安装JDK、Hadoop <a class="header-anchor" href="#安装jdk、hadoop" aria-label="Permalink to &quot;安装JDK、Hadoop&quot;">​</a></h2><blockquote><p>在hadoop102上安装。 在/opt 下创建module 和 software 文件夹用于安装软件 将jdk和hadoop上传到虚拟机/opt/software目录下</p></blockquote><h2 id="jdk" tabindex="-1">JDK <a class="header-anchor" href="#jdk" aria-label="Permalink to &quot;JDK&quot;">​</a></h2><p>解压文件</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tar</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -zxvf</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> jdk1.8.0_212.tar.gz</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -C</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /opt/module</span></span></code></pre></div><blockquote><p><code>tar -zxvf xx -C xxx</code> 是一个在Linux或类Unix系统中用来解压并提取tar文件的常用命令。这个命令的具体组成部分含义如下：</p><ul><li><code>tar</code>：是tape archive（磁带归档）的缩写，是Linux系统中用于归档和压缩文件的工具。</li><li><code>-z</code>：这个选项告诉tar命令使用gzip压缩算法来解压文件。当你看到文件名以<code>.tar.gz</code>或<code>.tgz</code>结尾时，通常需要使用这个选项。</li><li><code>-x</code>：表示要执行解压（extract）操作。也就是说，这个命令是要从归档文件中提取文件，而不是创建一个新的归档文件。</li><li><code>-v</code>：表示verbose模式，即详细模式。使用这个选项后，tar在执行操作时会显示更详细的信息，如正在处理的文件名等。</li><li><code>-f</code>：后面跟要操作的归档文件名。在这个命令中，<code>xx</code>代表你要解压的.tar.gz或.tgz文件的名称。需要注意，<code>-f</code>必须是最后一个选项，后面紧跟着归档文件名。</li><li><code>-C</code>：这个选项指定了解压的目标目录。后面的<code>xxx</code>是你希望解压后文件存放的目录路径。使用<code>-C</code>可以让tar在指定目录下解压文件，而不是当前工作目录。 综上所述，<code>tar -zxvf xx -C xxx</code> 命令的意思是：使用gzip解压方式，详细模式下解压名为<code>xx</code>的gzip压缩的tar文件，并将解压出来的文件放到<code>xxx</code>目录下。</li></ul></blockquote><p>配置jdk环境变量 （1）新建/etc/profile.d/my_env.sh 文件</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/profile.d/my_env.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 添加以下内容</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#JAVA_HOME</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/opt/module/jdk1.8.0_212</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PATH</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH:$JAVA_HOME/bin</span></span></code></pre></div><blockquote><p>linux环境变量在 <code>/etc/profile</code> 文件中，最后有一段脚本会遍历<code>/opt/profile.d</code>目录下的sh脚本，因此只需要在这个目录下创建一个sh脚本定义环境变量即可</p></blockquote><p>让环境变量生效</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">source</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/profile</span></span></code></pre></div><h3 id="hadoop" tabindex="-1">hadoop <a class="header-anchor" href="#hadoop" aria-label="Permalink to &quot;hadoop&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 解压</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tar</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -zxvf</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop-3.1.3.tar.gz</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -C</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /opt/module/</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置环境变量</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#HADOOP_HOME</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/opt/module/hadoop-3.1.3</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PATH</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH:$HADOOP_HOME/bin</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PATH</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH:$HADOOP_HOME/sbin</span></span></code></pre></div><p>记得source一下</p><p>目录结构：</p><ul><li>bin 存放Hadoop相关服务（hdfs、yarn、mapred）</li><li>etc 存放hadoop配置文件</li><li>lib 存放Hadoop本地库</li><li>sbin 存放启动或停止hadoop相关服务的脚本</li><li>share 存放hadoop依赖jar包、文档和官方案例</li></ul><h1 id="_3、hadoop生成环境集群搭建" tabindex="-1">3、Hadoop生成环境集群搭建 <a class="header-anchor" href="#_3、hadoop生成环境集群搭建" aria-label="Permalink to &quot;3、Hadoop生成环境集群搭建&quot;">​</a></h1><h2 id="本地模式" tabindex="-1">本地模式 <a class="header-anchor" href="#本地模式" aria-label="Permalink to &quot;本地模式&quot;">​</a></h2><h2 id="完全分布式集群" tabindex="-1">完全分布式集群 <a class="header-anchor" href="#完全分布式集群" aria-label="Permalink to &quot;完全分布式集群&quot;">​</a></h2>`,73),C=[_];function x(v,q,A,f,D,B){return i(),s("div",null,C)}const O=a(E,[["render",x]]);export{H as __pageData,O as default};
